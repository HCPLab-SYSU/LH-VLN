Path:
  scene: "/data2/songxinshuai/nav_gen/data/hm3d/"
  scene_dataset: "/data2/songxinshuai/nav_gen/data/hm3d/hm3d_annotated_basis.scene_dataset_config.json"
  
  episode_data: "/data2/songxinshuai/nav_gen/data/episode_task"
  task_data: "/data2/songxinshuai/nav_gen/data/task"
  step_task_data: "/data2/songxinshuai/nav_gen/data/step_task"
  train_batch: ['/batch_1', '/batch_2', '/batch_3', '/batch_4', '/batch_5']
  val_batch: ['/batch_6']
  test_batch: ['/batch_7', '/batch_8']
  split_by_scene: True

  save_checkpoints: "./save_checkpoints"

  tensorboard_path: "./run"
  output_dir: "./output"

Train:
  mode: 'train'
  tensorboard: False
  best_checkpoint: None
  load_checkpoint: False
  save_ckpt_per_epochs: 10

  batch_size: 1
  num_epochs: 20
  ignoreid: -100
  max_step: 500
  gradient_accumulation_step: 2
  num_warmup_steps: 1000

  success_dis: 1

Model:
  model_name: "LLM Model"
  pretrained_clip: "/data2/songxinshuai/nav_gen/data/models/clip-vit-base-patch16"
  bert_model: "/data2/songxinshuai/nav_gen/data/models/bert-large-uncased"
  pretrained_model_name_or_path: "/data2/LLM/Qwen2.5/Qwen-3B"
  resume_from_checkpoint: None
  from_scratch: True
  feat_dropout: 0.4
  temperature: 1.0
  image_feat_size: 1024
  angle_feat_size: 4
  enc_full_graph: True
  num_pano_layers: 2
  max_memory: 2

